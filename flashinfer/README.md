# FlashInfer 学习手册

欢迎来到 FlashInfer 学习手册！本手册专为新手设计，帮助你全面了解和掌握 FlashInfer。

## 📚 学习路径

我们建议按以下顺序阅读：

### 第一步：了解项目
1. **[仓库概述.md](./仓库概述.md)** - 了解 FlashInfer 是什么，有什么用
   - 项目的核心作用和用途
   - 应用场景和技术特色
   - 适合谁使用

### 第二步：深入理解
2. **[项目介绍.md](./项目介绍.md)** - 深入了解项目背景和核心概念
   - 项目背景和动机
   - 核心概念（FlashAttention、PageAttention 等）
   - 功能模块详解
   - 技术创新点

### 第三步：掌握架构
3. **[项目架构.md](./项目架构.md)** - 学习代码组织和设计模式
   - 整体架构设计
   - 目录结构详解
   - 核心设计模式
   - 构建系统

### 第四步：动手实践
4. **[快速上手.md](./快速上手.md)** - 开始使用 FlashInfer
   - 安装配置
   - 基础示例（从简单到复杂）
   - 常见问题解决
   - 完整 Demo

### 第五步：二次开发
5. **[二次开发指南.md](./二次开发指南.md)** - 扩展和定制 FlashInfer
   - 开发环境设置
   - 添加新功能
   - 性能优化
   - 代码贡献

### 第六步：第三方设备集成（高级）
6. **[第三方设备集成指南.md](./第三方设备集成指南.md)** - 移植到非 NVIDIA GPU
   - 国产 XPU 设备适配
   - AMD/Intel GPU 支持
   - 移植策略和技术路线
   - 完整案例（华为昇腾）

## 🎯 针对不同角色的阅读建议

### 🔰 完全新手
如果你对 LLM 推理优化不太了解：
1. 先读《仓库概述.md》了解这是什么
2. 再读《快速上手.md》跑通示例
3. 然后读《项目介绍.md》理解概念
4. 最后根据需要阅读其他文档

推荐学习时间：**3-5 小时**

### 👨‍💻 应用开发者
如果你想把 FlashInfer 集成到项目中：
1. 快速浏览《仓库概述.md》
2. 重点阅读《快速上手.md》
3. 参考《项目介绍.md》中的功能模块
4. 需要时查阅《二次开发指南.md》的集成部分

推荐学习时间：**2-3 小时**

### 🔧 系统开发者
如果你想优化或扩展 FlashInfer：
1. 阅读《仓库概述.md》和《项目介绍.md》建立全局认识
2. 深入学习《项目架构.md》理解设计
3. 仔细研读《二次开发指南.md》
4. 通过《快速上手.md》验证理解
5. 如需移植到其他设备，阅读《第三方设备集成指南.md》

推荐学习时间：**5-8 小时**（不含设备移植）

### 🎓 研究人员
如果你想研究 LLM 推理优化技术：
1. 先读《项目介绍.md》了解技术背景
2. 阅读《项目架构.md》理解实现
3. 通过《快速上手.md》实验验证
4. 参考《二次开发指南.md》进行改进

推荐学习时间：**6-10 小时**

## 📖 文档内容概览

### 仓库概述
- FlashInfer 的定位和作用
- 核心功能和应用场景
- 技术特色和优势
- 支持的硬件和软件

### 项目介绍
- 项目背景和动机
- FlashAttention、PageAttention 等核心概念
- 推理阶段详解（Prefill/Decode/Append）
- KV-Cache 管理
- 各功能模块介绍
- 技术创新点

### 项目架构
- 分层架构设计
- 目录结构详解
- 核心设计模式（模板元编程、Plan-Run 分离等）
- 构建系统
- 扩展点

### 快速上手
- 环境准备和安装
- 从简单到复杂的示例
- 单请求和批量处理
- 高级功能（PageAttention、采样、低精度）
- 性能优化技巧
- 常见问题解决

### 二次开发指南
- 开发环境设置
- 代码结构导航
- 实战案例（添加新算子、优化内核）
- 常见开发任务
- 调试和性能分析
- 代码规范
- 贡献代码流程

### 第三方设备集成指南
- 移植策略（完全重写 vs 转换工具）
- 技术挑战分析（CUDA 依赖、Tensor Core 等）
- 详细移植步骤（6 个阶段）
- 实战案例：华为昇腾移植
- 其他设备考虑（AMD、寒武纪、Intel）
- 性能优化和测试验证

## 🔗 相关资源

### 官方资源
- **官方网站**: https://flashinfer.ai
- **文档**: https://docs.flashinfer.ai
- **GitHub**: https://github.com/flashinfer-ai/flashinfer
- **论文**: https://arxiv.org/abs/2501.01005

### 社区
- **Slack**: 加入 FlashInfer 社区讨论
- **GitHub Discussions**: 技术讨论和问答
- **GitHub Issues**: 报告 bug 和功能请求

### 学习资源
- **CUDA 编程指南**: NVIDIA CUDA C Programming Guide
- **FlashAttention 论文**: 了解算法原理
- **vLLM**: 学习 LLM 推理系统设计
- **CUTLASS**: 学习高性能 CUDA 库设计

## 📝 使用建议

### 边学边练
- 不要只看不做，每个示例都运行一遍
- 修改参数观察结果变化
- 尝试组合不同的功能

### 查阅文档
- 遇到问题先查文档
- 参考 tests/ 目录下的测试用例
- 阅读源码注释

### 循序渐进
- 先掌握基础用法
- 再尝试高级功能
- 最后进行性能优化

### 积极交流
- 加入社区讨论
- 提问时提供完整信息
- 分享你的经验和发现

## 🚀 开始学习

现在就开始你的 FlashInfer 学习之旅吧！

**推荐起点**：

- 如果你是新手 → [仓库概述.md](./仓库概述.md)
- 如果想快速使用 → [快速上手.md](./快速上手.md)
- 如果想深入开发 → [项目架构.md](./项目架构.md)

## 💡 反馈与改进

如果你在使用这些学习材料时有任何问题或建议，欢迎：

1. 在 GitHub 上提 Issue
2. 在 Slack 社区讨论
3. 直接贡献改进（Pull Request）

你的反馈将帮助我们持续改进这份学习手册！

---

**最后更新**: 2025年11月
**适用版本**: FlashInfer v0.2.x

祝学习愉快！🎉

