# cuTile Python æ€§èƒ½è°ƒä¼˜è¯¦è§£

## ç›®å½•
1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æ¶æ„ç‰¹å®šé…ç½®ï¼ˆByTargetï¼‰](#æ¶æ„ç‰¹å®šé…ç½®bytarget)
3. [åŠ è½½/å­˜å‚¨æ€§èƒ½æç¤º](#åŠ è½½å­˜å‚¨æ€§èƒ½æç¤º)
4. [æ€§èƒ½è°ƒä¼˜ç­–ç•¥](#æ€§èƒ½è°ƒä¼˜ç­–ç•¥)
5. [å®æˆ˜ç¤ºä¾‹](#å®æˆ˜ç¤ºä¾‹)
6. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## æ¦‚è¿°

cuTile Python æä¾›äº†å¤šç§æ€§èƒ½è°ƒä¼˜æŠ€æœ¯ï¼Œå¸®åŠ©å¼€å‘è€…å……åˆ†å‘æŒ¥ GPU ç¡¬ä»¶çš„æ½œåŠ›ã€‚ä¸»è¦åŒ…æ‹¬ï¼š

### æ ¸å¿ƒè°ƒä¼˜æ‰‹æ®µ

1. **æ¶æ„ç‰¹å®šé…ç½®**ï¼šä½¿ç”¨ `ByTarget` é’ˆå¯¹ä¸åŒ GPU æ¶æ„å®šåˆ¶å‚æ•°
2. **å†…å­˜è®¿é—®æç¤º**ï¼šé€šè¿‡ `latency` å’Œ `allow_tma` ä¼˜åŒ–å†…å­˜æ“ä½œ
3. **å†…æ ¸é…ç½®ä¼˜åŒ–**ï¼šè°ƒæ•´ `num_ctas`ã€`occupancy` å’Œ `opt_level` ç­‰å‚æ•°

### ä¸ºä»€ä¹ˆéœ€è¦æ€§èƒ½è°ƒä¼˜ï¼Ÿ

ä¸åŒçš„ GPU æ¶æ„ï¼ˆå¦‚ SM_90ã€SM_100ã€SM_120ï¼‰å…·æœ‰ä¸åŒçš„ç¡¬ä»¶ç‰¹æ€§ï¼š
- **è®¡ç®—å•å…ƒæ•°é‡**ä¸åŒ
- **å†…å­˜å±‚æ¬¡ç»“æ„**å·®å¼‚
- **ç‰¹æ®Šç¡¬ä»¶åŠ é€Ÿå™¨**ï¼ˆå¦‚ TMAï¼‰çš„æ”¯æŒæƒ…å†µ

é€šè¿‡æ€§èƒ½è°ƒä¼˜ï¼Œå¯ä»¥ï¼š
- âœ… è®©åŒä¸€ä»½ä»£ç åœ¨ä¸åŒæ¶æ„ä¸Šéƒ½è¾¾åˆ°æœ€ä¼˜æ€§èƒ½
- âœ… é¿å…ç¡¬ä»¶èµ„æºæµªè´¹
- âœ… å‡å°‘å†…å­˜è®¿é—®å»¶è¿Ÿ
- âœ… æé«˜æ•´ä½“ååé‡

---

## æ¶æ„ç‰¹å®šé…ç½®ï¼ˆByTargetï¼‰

### ä»€ä¹ˆæ˜¯ ByTargetï¼Ÿ

`ByTarget` æ˜¯ä¸€ä¸ªç±»å‹ç±»ï¼Œå…è®¸ä½ ä¸ºä¸åŒçš„ GPU æ¶æ„æŒ‡å®šä¸åŒçš„é…ç½®å€¼ã€‚

```python
class cuda.tile.ByTarget(*, default=UNSPECIFIED, **value_by_target)
```

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `default` | Any | å›é€€å€¼ï¼Œå½“ç›®æ ‡æ¶æ„æœªæ˜¾å¼åˆ—å‡ºæ—¶ä½¿ç”¨ |
| `value_by_target` | dict | æ¶æ„åˆ°å€¼çš„æ˜ å°„ï¼Œé”®æ ¼å¼ä¸º `"sm_<major><minor>"` |

### æ”¯æŒçš„æ¶æ„æ ‡è¯†

| æ¶æ„æ ‡è¯† | å¯¹åº”ç¡¬ä»¶ | ç‰¹ç‚¹ |
|----------|----------|------|
| `sm_90` | H100 (Hopper) | TMA æ”¯æŒï¼Œçº¿ç¨‹å—é›†ç¾¤ |
| `sm_100` | B100 ç³»åˆ— (Blackwell) | å¢å¼ºçš„ TMAï¼Œæ›´å¤§çš„å…±äº«å†…å­˜ |
| `sm_120` | æœªæ¥æ¶æ„ | å¾…å®šç‰¹æ€§ |

### åŸºç¡€ç”¨æ³•

#### 1. ç»Ÿä¸€é…ç½®ï¼ˆæ‰€æœ‰æ¶æ„ç›¸åŒï¼‰

```python
from cuda.tile import kernel

@kernel(num_ctas=8)
def simple_kernel(x):
    """æ‰€æœ‰æ¶æ„éƒ½ä½¿ç”¨ 8 ä¸ª CTA"""
    pass
```

#### 2. æ¶æ„ç‰¹å®šé…ç½®ï¼ˆæ— å›é€€å€¼ï¼‰

```python
from cuda.tile import kernel, ByTarget

@kernel(num_ctas=ByTarget(sm_90=16, sm_100=8, sm_120=4))
def arch_specific_kernel(x):
    """
    - Hopper (sm_90): 16 ä¸ª CTA
    - Blackwell (sm_100): 8 ä¸ª CTA  
    - æœªæ¥æ¶æ„ (sm_120): 4 ä¸ª CTA
    """
    pass
```

#### 3. æ¶æ„ç‰¹å®šé…ç½®ï¼ˆå«å›é€€å€¼ï¼‰

```python
from cuda.tile import kernel, ByTarget

@kernel(num_ctas=ByTarget(sm_100=8, sm_120=4, default=2))
def kernel_with_fallback(x):
    """
    - Blackwell (sm_100): 8 ä¸ª CTA
    - æœªæ¥æ¶æ„ (sm_120): 4 ä¸ª CTA
    - å…¶ä»–æ‰€æœ‰æ¶æ„: 2 ä¸ª CTAï¼ˆå›é€€å€¼ï¼‰
    """
    pass
```

### å¯é…ç½®çš„å†…æ ¸å‚æ•°

`ByTarget` å¯ç”¨äºä»¥ä¸‹æ‰€æœ‰å†…æ ¸é…ç½®å‚æ•°ï¼š

#### 1. num_ctasï¼ˆCTA æ•°é‡ï¼‰

æ§åˆ¶åŒæ—¶è¿è¡Œçš„åä½œçº¿ç¨‹æ•°ç»„ï¼ˆCooperative Thread Arraysï¼‰æ•°é‡ã€‚

```python
@kernel(num_ctas=ByTarget(sm_90=16, sm_100=8, default=4))
def matmul_kernel(A, B, C):
    pass
```

**è°ƒä¼˜å»ºè®®ï¼š**
- æ›´æ–°çš„æ¶æ„é€šå¸¸èƒ½æ”¯æŒæ›´å¤šå¹¶å‘ CTA
- å¹³è¡¡å¹¶å‘åº¦ä¸èµ„æºæ¶ˆè€—ï¼ˆå¯„å­˜å™¨ã€å…±äº«å†…å­˜ï¼‰

#### 2. occupancyï¼ˆå ç”¨ç‡ï¼‰

æ§åˆ¶æ¯ä¸ª SM ä¸Šæ´»è·ƒçš„çº¿ç¨‹æ•°é‡ã€‚

```python
@kernel(occupancy=ByTarget(sm_90="max", sm_100=0.75, default=0.5))
def high_occupancy_kernel(x):
    pass
```

**è°ƒä¼˜å»ºè®®ï¼š**
- `"max"`ï¼šæœ€å¤§åŒ–å ç”¨ç‡ï¼ˆå¯èƒ½å¢åŠ å¯„å­˜å™¨æº¢å‡ºï¼‰
- `0.5-0.75`ï¼šå¹³è¡¡å ç”¨ç‡ä¸å¯„å­˜å™¨ä½¿ç”¨
- è¾ƒä½å€¼ï¼šç•™æ›´å¤šèµ„æºç»™å•ä¸ªçº¿ç¨‹

#### 3. opt_levelï¼ˆä¼˜åŒ–çº§åˆ«ï¼‰

æ§åˆ¶ç¼–è¯‘å™¨ä¼˜åŒ–å¼ºåº¦ã€‚

```python
@kernel(opt_level=ByTarget(sm_100=3, default=2))
def optimized_kernel(x):
    pass
```

**ä¼˜åŒ–çº§åˆ«ï¼š**
- `0`ï¼šæ— ä¼˜åŒ–ï¼ˆè°ƒè¯•ç”¨ï¼‰
- `1`ï¼šåŸºç¡€ä¼˜åŒ–
- `2`ï¼šæ ‡å‡†ä¼˜åŒ–ï¼ˆé»˜è®¤ï¼‰
- `3`ï¼šæ¿€è¿›ä¼˜åŒ–ï¼ˆå¯èƒ½å¢åŠ ç¼–è¯‘æ—¶é—´ï¼‰

### å®æˆ˜æ¡ˆä¾‹ï¼šçŸ©é˜µä¹˜æ³•ä¼˜åŒ–

```python
import cuda.tile as ct
from cuda.tile import ByTarget

# æ ¹æ®æ¶æ„ä¼˜åŒ– tile å¤§å°
TILE_M = ByTarget(sm_90=128, sm_100=256, default=64)
TILE_N = ByTarget(sm_90=128, sm_100=256, default=64)
TILE_K = 32

@ct.kernel(
    num_ctas=ByTarget(sm_90=16, sm_100=8, default=4),
    occupancy=ByTarget(sm_90="max", sm_100=0.75, default=0.5),
    opt_level=ByTarget(sm_100=3, default=2)
)
def optimized_matmul(A, B, C, M, N, K):
    """
    æ¶æ„æ„ŸçŸ¥çš„çŸ©é˜µä¹˜æ³•å†…æ ¸
    - sm_90: è¾ƒå° tileï¼Œé«˜å¹¶å‘
    - sm_100: æ›´å¤§ tileï¼Œä¸­ç­‰å¹¶å‘
    - å…¶ä»–: ä¿å®ˆé…ç½®
    """
    # è·å–å½“å‰æ¶æ„çš„ tile å¤§å°
    tile_m = ct.config.get_value(TILE_M)
    tile_n = ct.config.get_value(TILE_N)
    
    bid_x = ct.bid(0)
    bid_y = ct.bid(1)
    
    # ä½¿ç”¨åŠ¨æ€ tile å¤§å°
    tile_a = ct.load(A, index=(bid_x, 0), shape=(tile_m, TILE_K))
    tile_b = ct.load(B, index=(0, bid_y), shape=(TILE_K, tile_n))
    
    tile_c = ct.matmul(tile_a, tile_b)
    ct.store(C, index=(bid_x, bid_y), tile=tile_c)
```

---

## åŠ è½½/å­˜å‚¨æ€§èƒ½æç¤º

### æ¦‚è¿°

`load()` å’Œ `store()` æ“ä½œæ”¯æŒå¯é€‰çš„æ€§èƒ½æç¤ºå‚æ•°ï¼Œå¸®åŠ©ç¼–è¯‘å™¨ä¼˜åŒ–å†…å­˜è®¿é—®ã€‚

### å‚æ•°è¯¦è§£

#### 1. latencyï¼ˆå»¶è¿Ÿæç¤ºï¼‰

**ç±»å‹ï¼š** `int` æˆ– `None`

**å–å€¼èŒƒå›´ï¼š** 1ï¼ˆä½å»¶è¿Ÿï¼‰åˆ° 10ï¼ˆé«˜å»¶è¿Ÿï¼‰

**å«ä¹‰ï¼š** æŒ‡ç¤ºæ­¤æ“ä½œçš„ DRAM æµé‡å¯†é›†ç¨‹åº¦

```python
tile = ct.load(
    x, 
    index=(bid,), 
    shape=(TILE_SIZE,),
    latency=8  # æç¤ºï¼šè¿™æ˜¯ä¸€ä¸ªé«˜å»¶è¿Ÿçš„å†…å­˜è®¿é—®
)
```

**å…¸å‹å€¼ï¼š**
| latency å€¼ | åœºæ™¯ | è¯´æ˜ |
|------------|------|------|
| 1-3 | ä½å»¶è¿Ÿè®¿é—® | æ•°æ®å¯èƒ½åœ¨ç¼“å­˜ä¸­ï¼Œæˆ–è®¿é—®é¢‘ç¹ |
| 4-6 | ä¸­ç­‰å»¶è¿Ÿ | æ™®é€š DRAM è®¿é—® |
| 7-10 | é«˜å»¶è¿Ÿè®¿é—® | å¤§é‡æ•°æ®ä»å…¨å±€å†…å­˜è¯»å– |
| None | è‡ªåŠ¨æ¨æ–­ | è®©ç¼–è¯‘å™¨å†³å®šï¼ˆé»˜è®¤ï¼‰ |

#### 2. allow_tmaï¼ˆTMA ä½¿ç”¨æ§åˆ¶ï¼‰

**ç±»å‹ï¼š** `bool` æˆ– `None`

**å«ä¹‰ï¼š** æ§åˆ¶æ˜¯å¦å…è®¸ä½¿ç”¨ TMAï¼ˆTensor Memory Acceleratorï¼‰

```python
ct.store(
    y,
    index=(bid,),
    tile=tile_result,
    allow_tma=False  # ç¦æ­¢ä½¿ç”¨ TMA
)
```

**TMA ç‰¹æ€§ï¼š**
- âœ… **ä¼˜åŠ¿**ï¼šç¡¬ä»¶åŠ é€Ÿçš„å¼ é‡å†…å­˜æ“ä½œï¼Œæ›´é«˜å¸¦å®½
- âœ… **é€‚ç”¨**ï¼šå¤§å—è¿ç»­å†…å­˜ä¼ è¾“
- âŒ **é™åˆ¶**ï¼šä»…åœ¨æ”¯æŒçš„æ¶æ„ä¸Šå¯ç”¨ï¼ˆsm_90+ï¼‰
- âŒ **ä¸é€‚ç”¨**ï¼šå°è§„æ¨¡ã€ä¸è§„åˆ™è®¿é—®æ¨¡å¼

**å–å€¼ï¼š**
| å€¼ | è¡Œä¸º |
|----|------|
| `True` | å…è®¸ä½¿ç”¨ TMAï¼ˆå¦‚æœæ¶æ„æ”¯æŒï¼‰ |
| `False` | å¼ºåˆ¶ä¸ä½¿ç”¨ TMA |
| `None` | é»˜è®¤è¡Œä¸ºï¼ˆé€šå¸¸å…è®¸ TMAï¼‰ |

### æ€§èƒ½æç¤ºç­–ç•¥

#### ç­–ç•¥ 1ï¼šæ ¹æ®æ•°æ®å¤§å°è°ƒæ•´

```python
import cuda.tile as ct

def adaptive_load(data, index, shape, data_size_mb):
    """æ ¹æ®æ•°æ®å¤§å°è‡ªé€‚åº”é€‰æ‹© latency"""
    if data_size_mb < 1:
        latency_hint = 2  # å°æ•°æ®ï¼Œå¯èƒ½åœ¨ç¼“å­˜ä¸­
    elif data_size_mb < 10:
        latency_hint = 5  # ä¸­ç­‰æ•°æ®
    else:
        latency_hint = 9  # å¤§æ•°æ®ï¼Œé«˜å»¶è¿Ÿ
    
    return ct.load(data, index=index, shape=shape, latency=latency_hint)
```

#### ç­–ç•¥ 2ï¼šè®¿é—®æ¨¡å¼ä¼˜åŒ–

```python
@ct.kernel
def pattern_aware_kernel(input_data, temp_data, output_data):
    bid = ct.bid(0)
    
    # ç­–ç•¥ 1ï¼šé¦–æ¬¡ä»å…¨å±€å†…å­˜åŠ è½½ - é«˜å»¶è¿Ÿ
    tile_input = ct.load(
        input_data,
        index=(bid,),
        shape=(256,),
        latency=8,        # é¢„æœŸé«˜å»¶è¿Ÿ
        allow_tma=True    # å…è®¸ TMA åŠ é€Ÿ
    )
    
    # ä¸­é—´è®¡ç®—...
    tile_temp = ct.some_operation(tile_input)
    
    # ç­–ç•¥ 2ï¼šå†™å…¥ä¸´æ—¶æ•°æ® - ä¸­ç­‰å»¶è¿Ÿ
    ct.store(
        temp_data,
        index=(bid,),
        tile=tile_temp,
        latency=5,        # ä¸­ç­‰å»¶è¿Ÿ
        allow_tma=False   # å°æ•°æ®ä¸ç”¨ TMA
    )
    
    # ç­–ç•¥ 3ï¼šæœ€ç»ˆç»“æœå†™å› - ä½å»¶è¿Ÿï¼ˆå¯èƒ½è¢«ç¼“å­˜ï¼‰
    ct.store(
        output_data,
        index=(bid,),
        tile=tile_temp,
        latency=3,        # è¾ƒä½å»¶è¿Ÿ
        allow_tma=True
    )
```

#### ç­–ç•¥ 3ï¼šæ¶æ„æ„ŸçŸ¥çš„ TMA ä½¿ç”¨

```python
from cuda.tile import ByTarget

@ct.kernel
def architecture_aware_tma_kernel(x, y):
    bid = ct.bid(0)
    
    # åœ¨æ”¯æŒ TMA çš„æ¶æ„ä¸Šä½¿ç”¨
    use_tma = ct.config.get_compute_capability() >= 90  # sm_90+
    
    tile_x = ct.load(
        x,
        index=(bid,),
        shape=(1024,),
        latency=7,
        allow_tma=use_tma  # åŠ¨æ€å†³å®š
    )
    
    # å¤„ç†...
    ct.store(y, index=(bid,), tile=tile_x, allow_tma=use_tma)
```

### å®Œæ•´ç¤ºä¾‹ï¼šå¸¦æ€§èƒ½æç¤ºçš„å†…æ ¸

```python
import cuda.tile as ct

TILE_SIZE = 16

@ct.kernel
def load_store_with_hints_kernel(x, y):
    """æ¼”ç¤ºæ€§èƒ½æç¤ºçš„å®Œæ•´ä½¿ç”¨"""
    bid = ct.bid(0)
    
    # é«˜å»¶è¿Ÿ DRAM åŠ è½½
    tx = ct.load(
        x,
        index=(bid,),
        shape=(TILE_SIZE,),
        latency=8,        # æç¤ºï¼šé«˜å»¶è¿Ÿè®¿é—®
        allow_tma=True    # å…è®¸ TMA åŠ é€Ÿ
    )
    
    # å¯èƒ½çš„å¤„ç†...
    tx = tx * 2.0
    
    # è¾ƒä½å»¶è¿Ÿå†™å…¥
    ct.store(
        y,
        index=(bid,),
        tile=tx,
        latency=2,        # æç¤ºï¼šè¾ƒä¾¿å®œçš„å†™å…¥
        allow_tma=False   # ç¦ç”¨ TMAï¼ˆå°æ•°æ®ï¼‰
    )

# ä½¿ç”¨ç¤ºä¾‹
import numpy as np
from cuda import Device

# åˆ›å»ºæµ‹è¯•æ•°æ®
size = 1024
x_host = np.random.randn(size).astype(np.float32)
y_host = np.zeros(size, dtype=np.float32)

# åˆ†é…è®¾å¤‡å†…å­˜
x_device = Device.mem_alloc(x_host.nbytes)
y_device = Device.mem_alloc(y_host.nbytes)

# æ‹·è´æ•°æ®
Device.copy_htod(x_device, x_host)

# å¯åŠ¨å†…æ ¸
num_blocks = size // TILE_SIZE
load_store_with_hints_kernel[num_blocks](x_device, y_device)

# æ‹·è´ç»“æœ
Device.copy_dtoh(y_host, y_device)
```

---

## æ€§èƒ½è°ƒä¼˜ç­–ç•¥

### è°ƒä¼˜æµç¨‹

```
1. åŸºå‡†æµ‹è¯•
   â†“
2. è¯†åˆ«ç“¶é¢ˆ
   â†“
3. åº”ç”¨ä¼˜åŒ–
   â†“
4. éªŒè¯æ•ˆæœ
   â†“
5. è¿­ä»£æ”¹è¿›
```

### ç­–ç•¥çŸ©é˜µ

| ç“¶é¢ˆç±»å‹ | ä¼˜åŒ–æ‰‹æ®µ | ByTarget é…ç½® | å†…å­˜æç¤º |
|----------|----------|---------------|----------|
| è®¡ç®—å—é™ | æé«˜å ç”¨ç‡ | `occupancy="max"` | - |
| å†…å­˜å—é™ | TMA + latency ä¼˜åŒ– | - | `latency=8, allow_tma=True` |
| å¹¶å‘åº¦ä¸è¶³ | å¢åŠ  CTA | `num_ctas` å¢å¤§ | - |
| å¯„å­˜å™¨æº¢å‡º | é™ä½å ç”¨ç‡ | `occupancy=0.5` | - |

### å¸¸è§ä¼˜åŒ–æ¨¡å¼

#### æ¨¡å¼ 1ï¼šå†…å­˜å¯†é›†å‹åº”ç”¨

```python
@ct.kernel(
    num_ctas=ByTarget(sm_90=8, sm_100=4, default=2),
    occupancy=ByTarget(sm_90=0.5, default=0.25),  # é™ä½å ç”¨ç‡
    opt_level=3
)
def memory_intensive_kernel(large_array, result):
    """
    å†…å­˜å¯†é›†å‹ï¼š
    - è¾ƒå°‘ CTAï¼ˆå‡å°‘å†…å­˜ç«äº‰ï¼‰
    - è¾ƒä½å ç”¨ç‡ï¼ˆæ›´å¤šç¼“å­˜/å¯„å­˜å™¨ï¼‰
    - é«˜ä¼˜åŒ–çº§åˆ«
    """
    bid = ct.bid(0)
    
    # å¤§å—æ•°æ®åŠ è½½
    tile = ct.load(
        large_array,
        index=(bid,),
        shape=(4096,),
        latency=9,        # é«˜å»¶è¿Ÿ
        allow_tma=True    # å¯ç”¨ TMA
    )
    
    # å¤„ç†...
    processed = ct.reduce_sum(tile)
    
    # å†™å›å°ç»“æœ
    ct.store(
        result,
        index=(bid,),
        tile=processed,
        latency=1,
        allow_tma=False
    )
```

#### æ¨¡å¼ 2ï¼šè®¡ç®—å¯†é›†å‹åº”ç”¨

```python
@ct.kernel(
    num_ctas=ByTarget(sm_90=32, sm_100=16, default=8),
    occupancy="max",  # æœ€å¤§åŒ–å ç”¨ç‡
    opt_level=ByTarget(sm_100=3, default=2)
)
def compute_intensive_kernel(data, result):
    """
    è®¡ç®—å¯†é›†å‹ï¼š
    - æ›´å¤š CTAï¼ˆæé«˜å¹¶å‘ï¼‰
    - æœ€å¤§å ç”¨ç‡
    - è¾ƒå°çš„å†…å­˜è®¿é—®
    """
    bid = ct.bid(0)
    
    # å°æ•°æ®åŠ è½½
    tile = ct.load(
        data,
        index=(bid,),
        shape=(128,),
        latency=3,        # ä½å»¶è¿Ÿï¼ˆæ•°æ®å°ï¼‰
        allow_tma=False   # ä¸éœ€è¦ TMA
    )
    
    # å¤§é‡è®¡ç®—
    for _ in range(100):
        tile = ct.complex_computation(tile)
    
    ct.store(result, index=(bid,), tile=tile, latency=2)
```

#### æ¨¡å¼ 3ï¼šæ··åˆè´Ÿè½½

```python
@ct.kernel(
    num_ctas=ByTarget(sm_90=16, sm_100=12, default=6),
    occupancy=ByTarget(sm_90=0.75, sm_100=0.5, default=0.5),
    opt_level=2
)
def mixed_workload_kernel(input_data, weights, output):
    """
    æ··åˆè´Ÿè½½ï¼šå¹³è¡¡å†…å­˜å’Œè®¡ç®—
    """
    bid_x = ct.bid(0)
    bid_y = ct.bid(1)
    
    # è¾“å…¥æ•°æ® - ä¸­é«˜å»¶è¿Ÿ
    tile_input = ct.load(
        input_data,
        index=(bid_x,),
        shape=(512,),
        latency=6,
        allow_tma=True
    )
    
    # æƒé‡æ•°æ® - å¯èƒ½è¢«ç¼“å­˜
    tile_weights = ct.load(
        weights,
        index=(bid_y,),
        shape=(512,),
        latency=3,  # å‡è®¾æƒé‡ä¼šè¢«é‡ç”¨
        allow_tma=False
    )
    
    # è®¡ç®—
    result = ct.dot(tile_input, tile_weights)
    
    # è¾“å‡º
    ct.store(
        output,
        index=(bid_x, bid_y),
        tile=result,
        latency=4,
        allow_tma=True
    )
```

---

## å®æˆ˜ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šå‘é‡åŠ æ³•ä¼˜åŒ–

```python
import cuda.tile as ct
from cuda.tile import ByTarget
import numpy as np

# æ¶æ„æ„ŸçŸ¥çš„ tile å¤§å°
TILE_SIZE = ByTarget(sm_90=256, sm_100=512, default=128)

@ct.kernel(
    num_ctas=ByTarget(sm_90=16, sm_100=8, default=4),
    occupancy=ByTarget(sm_90="max", default=0.75)
)
def optimized_vector_add(a, b, c, n):
    """ä¼˜åŒ–çš„å‘é‡åŠ æ³•"""
    bid = ct.bid(0)
    tile_size = ct.config.get_value(TILE_SIZE)
    
    # è®¡ç®—å½“å‰å—çš„ç´¢å¼•èŒƒå›´
    start_idx = bid * tile_size
    
    # åŠ è½½è¾“å…¥ - å¹¶è¡Œå†…å­˜è®¿é—®
    tile_a = ct.load(
        a,
        index=(start_idx,),
        shape=(tile_size,),
        latency=5,
        allow_tma=True
    )
    
    tile_b = ct.load(
        b,
        index=(start_idx,),
        shape=(tile_size,),
        latency=5,
        allow_tma=True
    )
    
    # è®¡ç®—
    tile_c = tile_a + tile_b
    
    # å­˜å‚¨ç»“æœ
    ct.store(
        c,
        index=(start_idx,),
        tile=tile_c,
        latency=3,
        allow_tma=True
    )

# æ€§èƒ½æµ‹è¯•
def benchmark_vector_add():
    n = 1024 * 1024  # 1M å…ƒç´ 
    
    a = np.random.randn(n).astype(np.float32)
    b = np.random.randn(n).astype(np.float32)
    c = np.zeros(n, dtype=np.float32)
    
    # å¯åŠ¨ä¼˜åŒ–å†…æ ¸
    # num_blocks ä¼šæ ¹æ®æ¶æ„è‡ªåŠ¨è°ƒæ•´
    optimized_vector_add[n // 256](a, b, c, n)
    
    return c
```

### ç¤ºä¾‹ 2ï¼šçŸ©é˜µè½¬ç½®ä¼˜åŒ–

```python
import cuda.tile as ct
from cuda.tile import ByTarget

@ct.kernel(
    num_ctas=ByTarget(sm_90=16, sm_100=12, default=8),
    occupancy=0.75,
    opt_level=ByTarget(sm_100=3, default=2)
)
def optimized_transpose(input_matrix, output_matrix, rows, cols):
    """
    ä¼˜åŒ–çš„çŸ©é˜µè½¬ç½®
    - ä½¿ç”¨å…±äº«å†…å­˜é¿å… bank conflicts
    - æ¶æ„ç‰¹å®šçš„ tile å¤§å°
    """
    TILE_DIM = ByTarget(sm_90=32, sm_100=64, default=16)
    
    bid_x = ct.bid(0)
    bid_y = ct.bid(1)
    tid_x = ct.tid(0)
    tid_y = ct.tid(1)
    
    tile_dim = ct.config.get_value(TILE_DIM)
    
    # è¯»å–è¾“å…¥å— - è¿ç»­è®¿é—®
    x_index = bid_x * tile_dim + tid_x
    y_index = bid_y * tile_dim + tid_y
    
    # é«˜å»¶è¿ŸåŠ è½½ï¼ˆå¤§çŸ©é˜µï¼‰
    tile = ct.load(
        input_matrix,
        index=(x_index, y_index),
        shape=(tile_dim, tile_dim),
        latency=7,
        allow_tma=True  # å¤§å—ä¼ è¾“ç”¨ TMA
    )
    
    # è½¬ç½® tile
    tile_transposed = ct.transpose(tile)
    
    # å†™å…¥è¾“å‡º - äº¤æ¢åæ ‡
    out_x = bid_y * tile_dim + tid_x
    out_y = bid_x * tile_dim + tid_y
    
    ct.store(
        output_matrix,
        index=(out_x, out_y),
        tile=tile_transposed,
        latency=6,
        allow_tma=True
    )
```

### ç¤ºä¾‹ 3ï¼šå½’çº¦ï¼ˆReductionï¼‰ä¼˜åŒ–

```python
import cuda.tile as ct
from cuda.tile import ByTarget

@ct.kernel(
    num_ctas=ByTarget(sm_90=64, sm_100=32, default=16),
    occupancy="max",  # å½’çº¦å—ç›Šäºé«˜å ç”¨ç‡
    opt_level=3
)
def optimized_reduction(input_data, output, n):
    """
    ä¼˜åŒ–çš„å…¨å±€å½’çº¦
    - å¤šé˜¶æ®µå½’çº¦
    - å……åˆ†åˆ©ç”¨å…±äº«å†…å­˜
    """
    BLOCK_SIZE = ByTarget(sm_90=512, sm_100=1024, default=256)
    
    bid = ct.bid(0)
    tid = ct.tid(0)
    block_size = ct.config.get_value(BLOCK_SIZE)
    
    # ç¬¬ä¸€é˜¶æ®µï¼šåŠ è½½å¹¶è¿›è¡Œå—å†…å½’çº¦
    idx = bid * block_size + tid
    
    # åŠ è½½æ•°æ® - è·¨åº¦è®¿é—®
    tile = ct.load(
        input_data,
        index=(idx,),
        shape=(block_size,),
        latency=8,        # å¤§é‡æ•°æ®
        allow_tma=True
    )
    
    # å—å†…å½’çº¦
    partial_sum = ct.reduce_sum(tile)
    
    # ä½¿ç”¨åŸå­æ“ä½œç´¯åŠ åˆ°å…¨å±€ç»“æœ
    if tid == 0:
        # å†™å…¥éƒ¨åˆ†ç»“æœ - ä½å»¶è¿Ÿï¼ˆå°æ•°æ®ï¼‰
        ct.atomic_add(
            output,
            index=(0,),
            value=partial_sum
        )
```

### ç¤ºä¾‹ 4ï¼šå·ç§¯æ“ä½œä¼˜åŒ–

```python
import cuda.tile as ct
from cuda.tile import ByTarget

@ct.kernel(
    num_ctas=ByTarget(sm_90=24, sm_100=16, default=8),
    occupancy=ByTarget(sm_90=0.5, sm_100=0.75, default=0.5),
    opt_level=3
)
def optimized_conv2d(input_img, kernel, output, 
                     in_h, in_w, k_h, k_w, out_h, out_w):
    """
    ä¼˜åŒ–çš„ 2D å·ç§¯
    - é‡ç”¨è¾“å…¥æ•°æ®
    - TMA åŠ è½½å¤§å—æ•°æ®
    - æƒé‡ç¼“å­˜ä¼˜åŒ–
    """
    TILE_H = ByTarget(sm_90=16, sm_100=32, default=8)
    TILE_W = ByTarget(sm_90=16, sm_100=32, default=8)
    
    bid_x = ct.bid(0)
    bid_y = ct.bid(1)
    
    tile_h = ct.config.get_value(TILE_H)
    tile_w = ct.config.get_value(TILE_W)
    
    # åŠ è½½è¾“å…¥ tileï¼ˆåŒ…å« halo åŒºåŸŸï¼‰
    in_tile = ct.load(
        input_img,
        index=(bid_x * tile_h, bid_y * tile_w),
        shape=(tile_h + k_h - 1, tile_w + k_w - 1),
        latency=7,        # å›¾åƒæ•°æ®é€šå¸¸è¾ƒå¤§
        allow_tma=True    # è¿ç»­å†…å­˜ï¼Œé€‚åˆ TMA
    )
    
    # åŠ è½½å·ç§¯æ ¸ - å°æ•°æ®ï¼Œå¯èƒ½è¢«ç¼“å­˜
    kernel_tile = ct.load(
        kernel,
        index=(0, 0),
        shape=(k_h, k_w),
        latency=2,        # å°å†…æ ¸ï¼Œå¯èƒ½åœ¨ç¼“å­˜ä¸­
        allow_tma=False   # å¤ªå°ï¼Œä¸éœ€è¦ TMA
    )
    
    # æ‰§è¡Œå·ç§¯è®¡ç®—
    out_tile = ct.conv2d(in_tile, kernel_tile)
    
    # å­˜å‚¨è¾“å‡º
    ct.store(
        output,
        index=(bid_x * tile_h, bid_y * tile_w),
        tile=out_tile,
        latency=5,
        allow_tma=True
    )
```

---

## æœ€ä½³å®è·µ

### 1. æ¶æ„é…ç½®æœ€ä½³å®è·µ

#### âœ… æ¨èåšæ³•

```python
# 1. å§‹ç»ˆæä¾› default å€¼ï¼Œç¡®ä¿å‘åå…¼å®¹
@ct.kernel(num_ctas=ByTarget(sm_100=8, default=4))
def safe_kernel(x):
    pass

# 2. ä¸ºå…³é”®æ¶æ„æ˜¾å¼é…ç½®
@ct.kernel(
    num_ctas=ByTarget(sm_90=16, sm_100=8, default=4),
    occupancy=ByTarget(sm_90="max", sm_100=0.75, default=0.5)
)
def well_configured_kernel(x):
    pass

# 3. ä½¿ç”¨é…ç½®å¸¸é‡ï¼Œä¾¿äºç»´æŠ¤
SM90_CTAS = 16
SM100_CTAS = 8
DEFAULT_CTAS = 4

@ct.kernel(num_ctas=ByTarget(sm_90=SM90_CTAS, sm_100=SM100_CTAS, default=DEFAULT_CTAS))
def maintainable_kernel(x):
    pass
```

#### âŒ é¿å…çš„åšæ³•

```python
# 1. ä¸æä¾› defaultï¼Œå¯èƒ½åœ¨æ–°æ¶æ„ä¸Šå¤±è´¥
@ct.kernel(num_ctas=ByTarget(sm_90=8))  # å±é™©ï¼
def unsafe_kernel(x):
    pass

# 2. æ‰€æœ‰æ¶æ„ä½¿ç”¨ç›¸åŒé…ç½®ï¼ˆå¤±å»äº† ByTarget çš„æ„ä¹‰ï¼‰
@ct.kernel(num_ctas=ByTarget(sm_90=8, sm_100=8, sm_120=8, default=8))
def pointless_kernel(x):
    pass

# 3. ç¡¬ç¼–ç é­”æ•°
@ct.kernel(num_ctas=ByTarget(sm_90=16, sm_100=8, default=4))
@ct.kernel(num_ctas=ByTarget(sm_90=16, sm_100=8, default=4))  # é‡å¤é…ç½®
def redundant_kernels(x):
    pass
```

### 2. å†…å­˜è®¿é—®æœ€ä½³å®è·µ

#### âœ… æ¨èåšæ³•

```python
@ct.kernel
def good_memory_patterns(large_data, small_data, output):
    bid = ct.bid(0)
    
    # 1. å¤§æ•°æ®ï¼šé«˜ latency + TMA
    large_tile = ct.load(
        large_data,
        index=(bid,),
        shape=(4096,),
        latency=8,
        allow_tma=True
    )
    
    # 2. å°æ•°æ®/é¢‘ç¹è®¿é—®ï¼šä½ latencyï¼Œä¸ç”¨ TMA
    small_tile = ct.load(
        small_data,
        index=(bid,),
        shape=(16,),
        latency=2,
        allow_tma=False
    )
    
    # 3. æ ¹æ®è®¿é—®æ¨¡å¼è°ƒæ•´
    result = large_tile[:16] * small_tile
    
    ct.store(
        output,
        index=(bid,),
        tile=result,
        latency=3,
        allow_tma=False  # å°ç»“æœ
    )
```

#### âŒ é¿å…çš„åšæ³•

```python
@ct.kernel
def bad_memory_patterns(data, output):
    bid = ct.bid(0)
    
    # 1. å¤§æ•°æ®ä¸ä½¿ç”¨ TMAï¼ˆæµªè´¹æ€§èƒ½ï¼‰
    tile = ct.load(
        data,
        index=(bid,),
        shape=(4096,),
        allow_tma=False  # ä¸å¥½ï¼
    )
    
    # 2. æ‰€æœ‰æ“ä½œä½¿ç”¨ç›¸åŒçš„ latencyï¼ˆä¸ç²¾ç¡®ï¼‰
    ct.store(output, index=(bid,), tile=tile, latency=5)  # å¤ªç¬¼ç»Ÿ
    
    # 3. å°æ•°æ®ä½¿ç”¨ TMAï¼ˆå¼€é”€å¤§äºæ”¶ç›Šï¼‰
    small = ct.load(
        data,
        index=(bid,),
        shape=(4,),
        allow_tma=True  # æµªè´¹ï¼
    )
```

### 3. æ€§èƒ½è°ƒä¼˜æ£€æŸ¥æ¸…å•

#### è°ƒä¼˜å‰

- [ ] å»ºç«‹åŸºå‡†æ€§èƒ½ï¼ˆæœªä¼˜åŒ–ç‰ˆæœ¬ï¼‰
- [ ] è¯†åˆ«ç“¶é¢ˆï¼ˆè®¡ç®— vs å†…å­˜ï¼‰
- [ ] äº†è§£ç›®æ ‡æ¶æ„ç‰¹æ€§
- [ ] åˆ†ææ•°æ®è®¿é—®æ¨¡å¼

#### è°ƒä¼˜ä¸­

- [ ] åº”ç”¨æ¶æ„ç‰¹å®šé…ç½®ï¼ˆByTargetï¼‰
- [ ] è®¾ç½®åˆé€‚çš„ latency æç¤º
- [ ] å†³å®šæ˜¯å¦ä½¿ç”¨ TMA
- [ ] è°ƒæ•´ occupancy å’Œ num_ctas
- [ ] é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–çº§åˆ«

#### è°ƒä¼˜å

- [ ] æµ‹é‡æ€§èƒ½æå‡
- [ ] éªŒè¯ç»“æœæ­£ç¡®æ€§
- [ ] åœ¨å¤šä¸ªæ¶æ„ä¸Šæµ‹è¯•
- [ ] æ–‡æ¡£åŒ–é…ç½®é€‰æ‹©çš„åŸå› 

### 4. è°ƒè¯•æŠ€å·§

```python
import cuda.tile as ct
from cuda.tile import ByTarget

# æŠ€å·§ 1ï¼šä½¿ç”¨é…ç½®æ—¥å¿—
@ct.kernel(
    num_ctas=ByTarget(sm_90=16, sm_100=8, default=4),
    debug_info=True  # å¯ç”¨è°ƒè¯•ä¿¡æ¯
)
def debug_kernel(x):
    # è¿è¡Œæ—¶æ‰“å°é…ç½®
    if ct.tid(0) == 0 and ct.bid(0) == 0:
        print(f"Running on architecture: {ct.config.get_arch()}")
        print(f"Number of CTAs: {ct.config.get_num_ctas()}")
    pass

# æŠ€å·§ 2ï¼šæ€§èƒ½è®¡æ•°å™¨
@ct.kernel
def profiled_kernel(x, y):
    bid = ct.bid(0)
    
    # è®°å½•åŠ è½½æ—¶é—´
    start = ct.clock64()
    
    tile = ct.load(
        x,
        index=(bid,),
        shape=(256,),
        latency=5,
        allow_tma=True
    )
    
    load_time = ct.clock64() - start
    
    # å¯ä»¥å°†æ€§èƒ½æ•°æ®å†™å›
    # ...

# æŠ€å·§ 3ï¼šæ¸è¿›å¼ä¼˜åŒ–
def progressive_optimization():
    """ä»ç®€å•åˆ°å¤æ‚ï¼Œé€æ­¥ä¼˜åŒ–"""
    
    # é˜¶æ®µ 1ï¼šåŸºç¡€ç‰ˆæœ¬
    @ct.kernel
    def v1_basic(x, y):
        pass
    
    # é˜¶æ®µ 2ï¼šæ·»åŠ æ¶æ„é…ç½®
    @ct.kernel(num_ctas=ByTarget(sm_90=8, default=4))
    def v2_arch_aware(x, y):
        pass
    
    # é˜¶æ®µ 3ï¼šæ·»åŠ å†…å­˜æç¤º
    @ct.kernel(num_ctas=ByTarget(sm_90=8, default=4))
    def v3_memory_hints(x, y):
        # æ·»åŠ  latency å’Œ allow_tma
        pass
    
    # é˜¶æ®µ 4ï¼šå…¨é¢ä¼˜åŒ–
    @ct.kernel(
        num_ctas=ByTarget(sm_90=16, sm_100=8, default=4),
        occupancy=ByTarget(sm_90="max", default=0.75),
        opt_level=3
    )
    def v4_fully_optimized(x, y):
        # å®Œæ•´çš„æ€§èƒ½æç¤º
        pass
    
    # åœ¨æ¯ä¸ªé˜¶æ®µæµ‹é‡æ€§èƒ½
```

### 5. å¸¸è§é™·é˜±

#### é™·é˜± 1ï¼šè¿‡åº¦ä¼˜åŒ–

```python
# âŒ ä¸å¥½ï¼šè¿‡äºå¤æ‚ï¼Œéš¾ä»¥ç»´æŠ¤
@ct.kernel(
    num_ctas=ByTarget(
        sm_80=32, sm_86=28, sm_87=30, sm_89=26,
        sm_90=24, sm_100=20, sm_120=16, default=8
    ),
    occupancy=ByTarget(
        sm_80=0.9, sm_86=0.85, sm_87=0.87, sm_89=0.83,
        sm_90=0.8, sm_100=0.75, sm_120=0.7, default=0.5
    )
)
def over_optimized_kernel(x):
    pass

# âœ… å¥½ï¼šç®€æ´ï¼Œå…³æ³¨ä¸»è¦æ¶æ„
@ct.kernel(
    num_ctas=ByTarget(sm_90=24, sm_100=20, default=8),
    occupancy=ByTarget(sm_90=0.8, sm_100=0.75, default=0.5)
)
def well_balanced_kernel(x):
    pass
```

#### é™·é˜± 2ï¼šå¿½ç•¥æ•°æ®å¤§å°

```python
# âŒ ä¸å¥½ï¼šå°æ•°æ®ä½¿ç”¨é«˜å»¶è¿Ÿæç¤º
def process_small_array(data):
    tile = ct.load(
        data,
        index=(0,),
        shape=(16,),  # å¾ˆå°
        latency=9,    # ä¸åˆé€‚ï¼
        allow_tma=True  # æµªè´¹
    )

# âœ… å¥½ï¼šæ ¹æ®æ•°æ®å¤§å°è°ƒæ•´
def process_array_adaptively(data, size):
    if size < 64:
        latency_hint = 2
        use_tma = False
    elif size < 1024:
        latency_hint = 5
        use_tma = False
    else:
        latency_hint = 8
        use_tma = True
    
    tile = ct.load(
        data,
        index=(0,),
        shape=(size,),
        latency=latency_hint,
        allow_tma=use_tma
    )
```

#### é™·é˜± 3ï¼šä¸æµ‹è¯•å¤šæ¶æ„

```python
# âœ… å¥½ï¼šå¤šæ¶æ„æµ‹è¯•æ¡†æ¶
def test_across_architectures():
    import cuda.tile as ct
    
    @ct.kernel(num_ctas=ByTarget(sm_90=16, sm_100=8, default=4))
    def kernel(x, y):
        pass
    
    # æ¨¡æ‹Ÿä¸åŒæ¶æ„
    architectures = ["sm_90", "sm_100", "sm_80"]
    
    for arch in architectures:
        print(f"Testing on {arch}...")
        # è®¾ç½®ç›®æ ‡æ¶æ„
        ct.config.set_target_arch(arch)
        
        # è¿è¡Œæµ‹è¯•
        test_data = create_test_data()
        result = kernel(test_data)
        
        # éªŒè¯ç»“æœ
        assert verify_result(result), f"Failed on {arch}"
        
        print(f"âœ“ {arch} passed")
```

### 6. æ€§èƒ½æµ‹é‡æ¨¡æ¿

```python
import time
import numpy as np
import cuda.tile as ct
from cuda.tile import ByTarget

def benchmark_kernel(kernel_fn, input_data, num_iterations=100):
    """æ€§èƒ½æµ‹é‡é€šç”¨æ¨¡æ¿"""
    
    # é¢„çƒ­
    for _ in range(10):
        kernel_fn(input_data)
    
    # åŒæ­¥
    ct.device_synchronize()
    
    # è®¡æ—¶
    start = time.perf_counter()
    
    for _ in range(num_iterations):
        kernel_fn(input_data)
    
    ct.device_synchronize()
    end = time.perf_counter()
    
    # è®¡ç®—ç»Ÿè®¡
    avg_time_ms = (end - start) / num_iterations * 1000
    
    # è®¡ç®—å¸¦å®½ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
    data_size_gb = input_data.nbytes / 1e9
    bandwidth_gb_s = data_size_gb / (avg_time_ms / 1000)
    
    return {
        'avg_time_ms': avg_time_ms,
        'bandwidth_gb_s': bandwidth_gb_s,
        'iterations': num_iterations
    }

# ä½¿ç”¨ç¤ºä¾‹
@ct.kernel(num_ctas=ByTarget(sm_90=16, sm_100=8, default=4))
def my_optimized_kernel(x):
    pass

data = np.random.randn(1024 * 1024).astype(np.float32)
results = benchmark_kernel(my_optimized_kernel, data)

print(f"Average time: {results['avg_time_ms']:.3f} ms")
print(f"Bandwidth: {results['bandwidth_gb_s']:.2f} GB/s")
```

---

## æ€»ç»“

### å…³é”®è¦ç‚¹

1. **ByTarget** æ˜¯å®ç°æ¶æ„æ„ŸçŸ¥ä¼˜åŒ–çš„æ ¸å¿ƒå·¥å…·
2. **latency** å’Œ **allow_tma** å¸®åŠ©ç¼–è¯‘å™¨ä¼˜åŒ–å†…å­˜è®¿é—®
3. **æ€§èƒ½è°ƒä¼˜æ˜¯è¿­ä»£è¿‡ç¨‹**ï¼šæµ‹é‡ â†’ ä¼˜åŒ– â†’ éªŒè¯
4. **å¹³è¡¡æ˜¯å…³é”®**ï¼šä¸è¦è¿‡åº¦ä¼˜åŒ–ï¼Œä¿æŒä»£ç å¯ç»´æŠ¤æ€§

### ä¼˜åŒ–ä¼˜å…ˆçº§

```
1. ç¡®ä¿æ­£ç¡®æ€§ï¼ˆé¦–è¦ï¼‰
   â†“
2. è¯†åˆ«ä¸»è¦ç“¶é¢ˆ
   â†“
3. åº”ç”¨æ¶æ„ç‰¹å®šé…ç½®
   â†“
4. ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼
   â†“
5. å¾®è°ƒç»†èŠ‚å‚æ•°
```

### å­¦ä¹ è·¯å¾„

1. **å…¥é—¨é˜¶æ®µ**ï¼šç†è§£ `ByTarget` åŸºç¡€ç”¨æ³•
2. **è¿›é˜¶é˜¶æ®µ**ï¼šæŒæ¡ `latency` å’Œ `allow_tma` çš„ä½¿ç”¨
3. **é«˜çº§é˜¶æ®µ**ï¼šç»¼åˆè¿ç”¨æ‰€æœ‰ä¼˜åŒ–æŠ€æœ¯
4. **ä¸“å®¶é˜¶æ®µ**ï¼šé’ˆå¯¹ç‰¹å®šåº”ç”¨æ·±åº¦å®šåˆ¶

### è¿›ä¸€æ­¥å­¦ä¹ 

- ğŸ“– [cuTile æ‰§è¡Œæ¨¡å‹](execution-model.MD) - äº†è§£çº¿ç¨‹å’Œå—çš„ç»„ç»‡
- ğŸ“– [cuTile å†…å­˜æ¨¡å‹](memory-model.MD) - æ·±å…¥ç†è§£å†…å­˜åŒæ­¥
- ğŸ“– [cuTile æ•°æ®æ¨¡å‹](data-model.MD) - æŒæ¡æ•°æ®å¸ƒå±€ä¼˜åŒ–
- ğŸ“– [cuTile å¿«é€Ÿå…¥é—¨](quick-start.MD) - åŸºç¡€æ¦‚å¿µå›é¡¾

---

**æœ€åæ›´æ–°ï¼š** 2025-12-29

