# FX 符号追踪执行流程可视化

## 完整执行流程图

```
用户代码: fx.symbolic_trace(model)
          |
          ↓
    ┌─────────────────────────────┐
    │  symbolic_trace(model)      │  ← torch/fx/symbolic_trace.py
    │  - 创建 Tracer()             │
    │  - 调用 tracer.trace()      │
    └──────────┬──────────────────┘
               ↓
    ┌─────────────────────────────┐
    │  Tracer.trace(model)        │  ← torch/fx/_symbolic_trace.py
    │  [1] 获取 forward 方法       │
    │  [2] 分析函数签名            │
    │  [3] 创建 placeholder 节点   │
    │  [4] 用 Proxy 调用 forward   │
    │  [5] 创建 output 节点        │
    └──────────┬──────────────────┘
               ↓
    ┌─────────────────────────────┐
    │  创建 Proxy 对象             │  ← torch/fx/proxy.py
    │  Proxy(node, tracer)        │
    │  - 包装图节点                │
    │  - 重载魔术方法              │
    └──────────┬──────────────────┘
               ↓
    ┌─────────────────────────────┐
    │  执行 forward(proxy)        │
    │  遇到操作:                   │
    │  - y = self.linear(x)       │  → Proxy.__call__
    │  - z = torch.relu(y)        │  → Proxy.__torch_function__
    │  - w = y + z                │  → Proxy.__add__
    └──────────┬──────────────────┘
               ↓
    ┌─────────────────────────────┐
    │  Proxy 魔术方法触发          │
    │  调用 tracer.create_proxy()  │
    │  → tracer.create_node()     │
    │  → Graph.create_node()      │
    └──────────┬──────────────────┘
               ↓
    ┌─────────────────────────────┐
    │  Graph 中创建新 Node         │  ← torch/fx/graph.py
    │  - 生成唯一名称              │
    │  - 插入双向链表              │
    │  - 更新依赖关系              │
    └──────────┬──────────────────┘
               ↓
    ┌─────────────────────────────┐
    │  返回新的 Proxy              │
    │  包装新创建的 Node           │
    └──────────┬──────────────────┘
               ↓
    ┌─────────────────────────────┐
    │  forward 执行完成            │
    │  返回最终 Proxy              │
    └──────────┬──────────────────┘
               ↓
    ┌─────────────────────────────┐
    │  Tracer 创建 output 节点     │
    │  返回完整 Graph              │
    └──────────┬──────────────────┘
               ↓
    ┌─────────────────────────────┐
    │  创建 GraphModule            │  ← torch/fx/graph_module.py
    │  [1] 复制原模块属性          │
    │  [2] 从 Graph 生成代码       │
    │  [3] exec 编译代码           │
    │  [4] 绑定 forward 方法       │
    └──────────┬──────────────────┘
               ↓
    ┌─────────────────────────────┐
    │  返回 GraphModule            │
    │  - 可执行                    │
    │  - 可编辑                    │
    │  - 可序列化                  │
    └─────────────────────────────┘
```

---

## 关键数据流

### 从 Python 代码到图节点

```python
# 用户代码
def forward(self, x):
    y = self.linear(x)
    z = torch.relu(y)
    return z
```

↓

```
追踪过程:

[Step 1] 创建 placeholder
    x_proxy = Proxy(Node(op='placeholder', name='x'))

[Step 2] 执行 y = self.linear(x)
    触发: Module.__call__
    拦截: Tracer.call_module()
    创建: Node(op='call_module', target='linear', args=(x_node,))
    返回: y_proxy = Proxy(linear_node)

[Step 3] 执行 z = torch.relu(y)
    触发: Proxy.__torch_function__(torch.relu, ...)
    创建: Node(op='call_function', target=torch.relu, args=(y_node,))
    返回: z_proxy = Proxy(relu_node)

[Step 4] return z
    创建: Node(op='output', args=(z_node,))
```

↓

```
生成的 Graph:

placeholder('x') → call_module('linear', x) → call_function(torch.relu, linear) → output(relu)
```

↓

```python
# 生成的代码:
def forward(self, x):
    linear = self.linear(x);  x = None
    relu = torch.relu(linear);  linear = None
    return relu
```

---

## 数据结构关系图

```
┌─────────────────┐
│  GraphModule    │
│                 │
│  - graph: Graph │───────┐
│  - forward()    │       │
│  - code: str    │       │
└─────────────────┘       │
                          │
                          ↓
                  ┌─────────────────┐
                  │     Graph       │
                  │                 │
                  │  - _root: Node  │
                  │  - nodes: List  │
                  └────────┬────────┘
                           │
                           │ 包含
                           ↓
         ┌──────────────────────────────────┐
         │             Node                 │
         │                                  │
         │  - name: str   (如: 'linear')    │
         │  - op: str     (如: 'call_module')│
         │  - target: Any (如: 'linear')    │
         │  - args: Tuple                   │
         │  - kwargs: Dict                  │
         │  - users: Dict[Node]             │
         │  - prev: Node                    │
         │  - next: Node                    │
         └────────┬───────────────────────┘
                  │
                  │ 被包装
                  ↓
         ┌──────────────────┐
         │     Proxy        │
         │                  │
         │  - node: Node    │
         │  - tracer: Tracer│
         │  - __add__()     │
         │  - __call__()    │
         │  - __torch_...() │
         └──────────────────┘
```

---

## Proxy 魔术方法覆盖表

| Python 操作 | 魔术方法 | 生成的节点 |
|------------|---------|-----------|
| `x + y` | `__add__` | `call_function(operator.add, x, y)` |
| `x * y` | `__mul__` | `call_function(operator.mul, x, y)` |
| `x - y` | `__sub__` | `call_function(operator.sub, x, y)` |
| `x / y` | `__truediv__` | `call_function(operator.truediv, x, y)` |
| `x == y` | `__eq__` | `call_function(operator.eq, x, y)` |
| `x < y` | `__lt__` | `call_function(operator.lt, x, y)` |
| `x[0]` | `__getitem__` | `call_function(operator.getitem, x, 0)` |
| `len(x)` | `__len__` | `call_function(len, x)` |
| `x.shape` | `__getattr__` | `call_function(getattr, x, 'shape')` |
| `x.view(-1)` | `__call__` | `call_method('view', x, -1)` |
| `torch.relu(x)` | `__torch_function__` | `call_function(torch.relu, x)` |
| `self.linear(x)` | Module hook | `call_module('linear', x)` |

---

## 追踪流程时序图

```
用户           Tracer         Graph          Proxy          Node
 │               │             │              │              │
 │─symbolic_trace→│             │              │              │
 │               │             │              │              │
 │               │─create──────→│              │              │
 │               │             Graph           │              │
 │               │             │              │              │
 │               │──────────────────create────→│              │
 │               │             │         Proxy(x)            │
 │               │             │              │              │
 │               │             │              │←─create──────│
 │               │             │              │         Node('x')
 │               │             │              │              │
 │──forward(proxy)→             │              │              │
 │               │             │              │              │
 │  y=linear(x)  │             │              │              │
 │               │←────────────────__call__───│              │
 │               │             │              │              │
 │               │─create_node→│              │              │
 │               │             │──new Node────→              │
 │               │             │              │ Node('linear')
 │               │             │              │              │
 │               │─create_proxy→              │              │
 │               │             │←─new Proxy──│              │
 │               │             │        Proxy(linear)       │
 │               │             │              │              │
 │  z=relu(y)    │             │              │              │
 │               │←──────────__torch_function__│              │
 │               │             │              │              │
 │               │─create_node→│              │              │
 │               │             │──new Node────────────────→ │
 │               │             │              │    Node('relu')
 │               │             │              │              │
 │               │─create_proxy→              │              │
 │               │             │←─new Proxy──│              │
 │               │             │        Proxy(relu)         │
 │               │             │              │              │
 │  return z     │             │              │              │
 │               │             │              │              │
 │               │─output_node→│              │              │
 │               │             │──new Node────────────────→ │
 │               │             │              │  Node('output')
 │               │             │              │              │
 │←─GraphModule──│             │              │              │
```

---

## 代码生成过程

### Graph 到 Python Code 的转换

```python
# Graph 结构
Graph:
  Node('x', op='placeholder')
  Node('linear', op='call_module', target='linear', args=(x,))
  Node('relu', op='call_function', target=torch.relu, args=(linear,))
  Node('output', op='output', args=(relu,))
```

↓ **Graph.python_code()**

```python
# 第一步: 收集 placeholder
placeholders = ['x']

# 第二步: 遍历节点生成语句
statements = [
    "linear = self.linear(x);  x = None",
    "relu = torch.relu(linear);  linear = None",
]

# 第三步: 生成 return
return_stmt = "return relu"

# 第四步: 组装
code = f"""
def forward(self, x):
    linear = self.linear(x);  x = None
    relu = torch.relu(linear);  linear = None
    return relu
"""
```

↓ **exec() + 绑定**

```python
# 编译
local_dict = {}
exec(code, globals, local_dict)

# 绑定
self.forward = local_dict['forward'].__get__(self, GraphModule)
```

---

## 核心源码位置速查表

| 功能 | 文件路径 | 关键类/函数 | 行数估计 |
|-----|---------|-----------|---------|
| **入口** | `torch/fx/symbolic_trace.py` | `symbolic_trace()` | ~50 |
| **追踪器** | `torch/fx/_symbolic_trace.py` | `Tracer.trace()` | ~800 |
| **代理** | `torch/fx/proxy.py` | `Proxy`, `__add__`, `__torch_function__` | ~300 |
| **图** | `torch/fx/graph.py` | `Graph.create_node()`, `python_code()` | ~500 |
| **节点** | `torch/fx/node.py` | `Node`, `format_node()` | ~300 |
| **模块** | `torch/fx/graph_module.py` | `GraphModule.recompile()` | ~400 |

**总计核心代码**: ~2350 行

---

## 执行示例对比

### 原始 PyTorch 执行

```python
x = torch.randn(10)
y = model.linear(x)     # 实际计算
z = torch.relu(y)       # 实际计算
```

**每一步都会真实计算并分配内存**

### FX 追踪执行

```python
x = Proxy(Node('x'))           # 不计算,只记录
y = model.linear(x)            # 不计算,只记录
  → y = Proxy(Node('linear'))
z = torch.relu(y)              # 不计算,只记录
  → z = Proxy(Node('relu'))
```

**不做真实计算,只构建图结构**

### 追踪完成后执行

```python
traced_model(real_input)
  → 执行生成的 forward 代码
  → 每步都是真实计算
```

**使用优化后的图进行计算**

---

## 关键技术点总结

### 1. **Proxy 拦截机制**
- 通过重载 `__add__`, `__mul__` 等魔术方法
- 拦截所有操作并转换为图节点
- 不执行真实计算,只记录操作

### 2. **__torch_function__ 协议**
- PEP 648 标准
- 拦截 `torch.*` 函数调用
- 允许自定义 Tensor-like 类型

### 3. **双向链表图结构**
- 高效的节点插入/删除
- 方便的前向/后向遍历
- 自动维护依赖关系

### 4. **动态代码生成**
- 从图生成 Python 代码字符串
- 使用 `exec()` 动态编译
- 性能接近手写代码

### 5. **模块保留**
- 保留原模块的所有参数和子模块
- 只替换 forward 方法
- 保持模型的可训练性

---

## 扩展阅读

1. **PEP 648**: __torch_function__ 协议
2. **Python AST**: 抽象语法树
3. **元编程**: exec, compile, types.FunctionType
4. **设计模式**: 代理模式, 访问者模式

---

*该文档配合《FX符号追踪源码深度剖析.md》阅读效果更佳*

